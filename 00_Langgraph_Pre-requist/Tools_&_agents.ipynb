{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY   = os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHIAN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHIAN_PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name= \"all-MiniLM-L6-V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model = \"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have feelings, but I'm here and ready to assist you! How can I help you today? 😄\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 15, 'total_tokens': 48, 'completion_time': 0.06, 'prompt_time': 0.001906966, 'queue_time': 0.231663185, 'total_time': 0.061906966}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-58e3f73d-afb6-45d2-8f88-1536b46a51d8-0', usage_metadata={'input_tokens': 15, 'output_tokens': 33, 'total_tokens': 48})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefined tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence (Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing training data. This allows LLMs to use domain-specific and/or updated information.  Use cases include providing chatbot access to internal company data or generating responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases.\n",
      "By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining. According to IBM, \"RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\"\n",
      "Beyond efficiency gains, RAG also allows LLMs to include source references in their responses, enabling users to verify information by reviewing cited documents or original sources. This can provide greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\" Return the length of word.\"\"\"\n",
    "    return len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(get_word_length(\"bhushan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"adding two numbers\"\n",
    "    return a+b\n",
    "\n",
    "a = 9\n",
    "b = 10\n",
    "multiply.invoke({\"a\":a,\"b\":b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n",
      "adding two numbers\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.args)\n",
    "print(multiply.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts of Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This agents class from first version of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tool=load_tools([\"wikipedia\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to look up \"llama\" on Wikipedia to see what it refers to and who created it. \n",
      "Action: wikipedia\n",
      "Action Input: llama language model\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhat is llama and who create this llm model?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\chains\\base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\agents\\agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1624\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1634\u001b[0m         )\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\agents\\agent.py:1415\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m-> 1415\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain\\agents\\agent.py:1437\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[1;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m-> 1437\u001b[0m     observation \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1438\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[0;32m   1439\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1440\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   1441\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1442\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[0;32m   1443\u001b[0m     )\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1445\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_core\\tools\\base.py:763\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    762\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    764\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    765\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_core\\tools\\base.py:732\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    731\u001b[0m     tool_kwargs \u001b[38;5;241m=\u001b[39m tool_kwargs \u001b[38;5;241m|\u001b[39m {config_param: config}\n\u001b[1;32m--> 732\u001b[0m response \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_community\\tools\\wikipedia\\tool.py:38\u001b[0m, in \u001b[0;36mWikipediaQueryRun._run\u001b[1;34m(self, query, run_manager)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run\u001b[39m(\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     34\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     35\u001b[0m     run_manager: Optional[CallbackManagerForToolRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Use the Wikipedia tool.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_community\\utilities\\wikipedia.py:55\u001b[0m, in \u001b[0;36mWikipediaAPIWrapper.run\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_title \u001b[38;5;129;01min\u001b[39;00m page_titles[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k_results]:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wiki_page \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_page(page_title):\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m summary \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_formatted_page_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwiki_page\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     56\u001b[0m             summaries\u001b[38;5;241m.\u001b[39mappend(summary)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m summaries:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\langchain_community\\utilities\\wikipedia.py:63\u001b[0m, in \u001b[0;36mWikipediaAPIWrapper._formatted_page_summary\u001b[1;34m(page_title, wiki_page)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_formatted_page_summary\u001b[39m(page_title: \u001b[38;5;28mstr\u001b[39m, wiki_page: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_title\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mwiki_page\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\wikipedia\\wikipedia.py:530\u001b[0m, in \u001b[0;36mWikipediaPage.summary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    528\u001b[0m      query_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpageids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpageid\n\u001b[1;32m--> 530\u001b[0m   request \u001b[38;5;241m=\u001b[39m \u001b[43m_wiki_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary \u001b[38;5;241m=\u001b[39m request[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpageid][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\wikipedia\\wikipedia.py:737\u001b[0m, in \u001b[0;36m_wiki_request\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    734\u001b[0m   wait_time \u001b[38;5;241m=\u001b[39m (RATE_LIMIT_LAST_CALL \u001b[38;5;241m+\u001b[39m RATE_LIMIT_MIN_WAIT) \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    735\u001b[0m   time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mint\u001b[39m(wait_time\u001b[38;5;241m.\u001b[39mtotal_seconds()))\n\u001b[1;32m--> 737\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RATE_LIMIT:\n\u001b[0;32m    740\u001b[0m   RATE_LIMIT_LAST_CALL \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\http\\client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\http\\client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 976\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_connected_to_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.run(\"what is llama and who create this llm model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Weather in San Francisco',\n",
       "  'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1742054588, 'localtime': '2025-03-15 09:03'}, 'current': {'last_updated_epoch': 1742054400, 'last_updated': '2025-03-15 09:00', 'temp_c': 11.1, 'temp_f': 52.0, 'is_day': 1, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/day/143.png', 'code': 1030}, 'wind_mph': 5.8, 'wind_kph': 9.4, 'wind_degree': 238, 'wind_dir': 'WSW', 'pressure_mb': 1020.0, 'pressure_in': 30.12, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 77, 'cloud': 75, 'feelslike_c': 10.1, 'feelslike_f': 50.1, 'windchill_c': 8.4, 'windchill_f': 47.1, 'heatindex_c': 9.6, 'heatindex_f': 49.3, 'dewpoint_c': 5.7, 'dewpoint_f': 42.3, 'vis_km': 8.0, 'vis_miles': 4.0, 'uv': 0.8, 'gust_mph': 8.0, 'gust_kph': 12.9}}\",\n",
       "  'score': 0.9501072},\n",
       " {'title': 'Saturday, March 15, 2025. San Francisco, CA - Weather Forecast',\n",
       "  'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/march/2025-03-15',\n",
       "  'content': 'Rainy weather, precipitation in the form of water droplets falling from the sky. Day 59°. Night 50°. Precipitation 55 %. Wind 9 mph. UV Index (',\n",
       "  'score': 0.9314689},\n",
       " {'title': 'Weather in San Francisco in March 2025 (California)',\n",
       "  'url': 'https://world-weather.info/forecast/usa/san_francisco/march-2025/',\n",
       "  'content': \"Weather in San Francisco in March 2025 (California) - Detailed Weather Forecast for a Month Weather in San Francisco Weather in San Francisco in March 2025 San Francisco Weather Forecast for March 2025 is based on long term prognosis and previous years' statistical data. 1 +54°+52° 2 +54°+50° 3 +54°+50° 4 +54°+48° 5 +61°+46° +59°+50° +59°+50° +61°+50° +61°+52° +61°+52° +63°+52° +63°+52° +61°+52° +61°+52° +63°+54° +61°+52° +63°+50° +61°+52° +61°+52° +59°+52° +61°+52° +59°+50° +57°+50° +57°+50° +59°+50° +59°+50° +61°+52° +63°+52° +63°+54° +63°+52° +63°+54° Extended weather forecast in San Francisco HourlyWeek10-Day14-Day30-DayYear Weather in Washington, D.C.+32° Sacramento+55° Pleasanton+52° Redwood City+55° San Leandro+55° San Mateo+54° San Rafael+55° San Ramon+52° South San Francisco+54° Vallejo+54° Palo Alto+55° Pacifica+55° Berkeley+57° Castro Valley+54° Concord+54° Daly City+54° Lagunitas+55° world's temperature today day day Temperature units\",\n",
       "  'score': 0.8437023},\n",
       " {'title': 'San Francisco weather in March 2025 | Weather25.com',\n",
       "  'url': 'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=March',\n",
       "  'content': 'San Francisco weather in March 2025 | Weather25.com San Francisco weather in March 2025 | San Francisco in March | Temperatures in San Francisco in March Weather in San Francisco in March - FAQ The average temperature in San Francisco in March is 8/17° C. On average, there are 5 rainy days in San Francisco during March. The weather in San Francisco in March is good. On average, there are 0 snowy days in San Francisco in March. More about the weather in San Francisco San Francisco 14 day weather Long range weather for San Francisco San Francisco weather in November San Francisco weather in December San Francisco Webcam Weather tomorrow Hotels in San Francisco',\n",
       "  'score': 0.81875163},\n",
       " {'title': 'San Francisco Bay Area March 15, 2025 - YouTube',\n",
       "  'url': 'https://www.youtube.com/watch?v=eoT-iJxTqBU',\n",
       "  'content': 'KRON4 meteorologist Kathy Trafton forecasts the weather.',\n",
       "  'score': 0.6350646}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Time in United States now',\n",
       "  'url': 'https://time.is/United_States',\n",
       "  'content': 'Time.is Time in United States now United States switches to daylight saving time at 02:00AM on Sunday, March 9. The time zone for the capital Washington, D.C. is used here. Sun: ↑ 06:32AM ↓ 06:07PM (11h 34m) - More info - Make United States time default - Add to favorite locations Time zone info for United States From 9 March 2025: UTC -4 / Eastern Daylight Time (EDT) The IANA time zone identifier for United States is America/New_York. Switched to UTC -5 / Eastern Standard Time (EST). Time difference Compare other time zones Exact time now Time here&there Your time zone Time zones Time zone news How to use Time.is What time is it? ¿Qué hora es?',\n",
       "  'score': 0.72629017},\n",
       " {'title': 'Time.gov',\n",
       "  'url': 'https://www.time.gov/',\n",
       "  'content': \"National Institute of Standards and Technology | NIST OFFICIAL U.S. TIME Alaska Standard Time AKST (UTC-9) Aleutian Standard Time HAST (UTC-10) 10:18:20 P.M. Hawaii Standard Time HST (UTC-10) Samoa Standard Time SST (UTC-11) 09:18:20 P.M. Chamorro Standard Time CHST (UTC+10) 06:18:20 P.M. Atlantic Standard Time AST (UTC-4) 04:18:20 A.M. Pacific Standard Time PST (UTC-8) 12:18:20 A.M. Mountain Standard Time MST (UTC-7) 01:18:20 A.M. Central Standard Time CST (UTC-6) 02:18:20 A.M. Eastern Standard Time EST (UTC-5) Standard Time MST (UTC-7) 01:18:20 A.M. Coordinated Universal Time (UTC) UTC is always displayed as a 24-hour clock. Your Device's Clock UTC-0 Atlantic Standard Time AST (UTC-4) Privacy Statement Privacy Policy NIST No Fear Act Policy Disclaimer Environmental Policy Statement Cookie Disclaimer NIST Information Quality Standards\",\n",
       "  'score': 0.67527276},\n",
       " {'title': 'Time in the United States',\n",
       "  'url': 'https://www.timeanddate.com/worldclock/usa',\n",
       "  'content': 'Home \\xa0 Time Zones \\xa0 World Clock \\xa0 United States Current Local Time in the United States Time Zone Multiple Time Zones Total Time Zones:   12 (with dependencies) Time Zones in USA See all Time Zones in United States Time in States and Federal Districts in USA (51 States and Federal Districts Listed Below, 13 States and Federal Districts Have Multiple Time Zones) Alaska (Aleutian Islands)   Fri 10:33 pm    Kentucky (western part) Sat 2:33 am Oklahoma    Sat 2:33 am Idaho   Sat 1:33 am New Jersey  Sat 3:33 am Washington  Sat 12:33 am territory    Hagåtña Sat 6:33 pm territory    Saipan  Sat 6:33 pm Time Zone Converter for Washington DC Event Time Announcer for Washington DC Time difference between Washington DC and other locations Los Angeles International Airport, LAX Contact Details Privacy Policy Time Zones',\n",
       "  'score': 0.6002124},\n",
       " {'title': 'Current local time in United States - 24 Time Zones',\n",
       "  'url': 'https://24timezones.com/United-States/time',\n",
       "  'content': 'Chicago, Houston, San Antonio, Dallas Anchorage, Juneau, Fairbanks, Unalaska United States time zones Chicago, Houston, San Antonio, Dallas: Anchorage, Juneau, Fairbanks, Unalaska: New York Los Angeles Chicago Houston Philadelphia Phoenix San Antonio San Diego Dallas San Jose (USA) Austin Jacksonville San Francisco Columbus Fort Worth Indianapolis Charlotte Seattle Denver El Paso Detroit Boston Memphis Portland Oklahoma City Las Vegas Baltimore Washington Milwaukee Albuquerque Tucson Nashville Sacramento Kansas City Long Beach Mesa Atlanta Virginia Beach Raleigh Miami Oakland Minneapolis Wichita New Orleans Arlington Cleveland Honolulu Tampa Aurora Anaheim Current local time in United States - standard offset to GMT, summer/winter time United States dates, offset to GMT/UTC, daylight savings time (DST), free United States online analog Html clock, and time conversion 2025 dates.',\n",
       "  'score': 0.5479727},\n",
       " {'title': 'Current Local Time in New York, New York, USA - Time and Date',\n",
       "  'url': 'https://www.timeanddate.com/worldclock/usa/new-york',\n",
       "  'content': 'Current Local Time in New York, New York, USA Time Zone News Calendar & Holiday News Time Zones Time Zones Home Time Zone Converter Time Zone News Calendar & Holiday News Sun & Moon Home Moon Calculator Calculators Home \\xa0 Time Zones \\xa0 World Clock \\xa0 USA \\xa0 New York Current Local Time in New York, New York, USA Time Zone Sunrise & Sunset Time Zone More Sun & Moon in New York Time Zone Converter for New York Event Time Announcer for New York Time difference between New York and other locations Distance calculator to/from New York Calendar & Holidays Sun & Moon times precise to the second. © Time and Date AS 1995–2025 Time Zones Calculators © Time and Date AS 1995–2025.',\n",
       "  'score': 0.24599452}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is time in U.S?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000193D561D120>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000193D561D120>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "tools = [search]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'how are you'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'How are you? | Emotions song for children | English Through Music', 'url': 'https://www.youtube.com/watch?v=fMR8Hr9Xby4', 'content': \"How are you? |  Emotions song for children | English Through Music\\nEnglishThroughMusic Madrid\\n20900 subscribers\\n9480 likes\\n2593919 views\\n22 Oct 2015\\nLYRICS:\\nI'm happy, I'm happy, I'm happy, I'm very happy (x2)\\nHow are you? How are you? How are you, today?\\nI'm sad, I'm sad, I'm sad I'm very sad (x2)\\nI'm angry\\nI'm tired\\nI'm hungry\\n\\nHow are you?  Song to teach emotions to young children kids with fun dance moves.\\n\\nGo to http://www.englishthroughmusic.es for more information about English Through Music, including more songs, raps, and videos for learning and teaching English.\\n\\nVOCABULARY: Happy, Sad, Angry Tired, Hungry, very, how are you?\\nGRAMMAR: I'm (Instead of 'I am' for correct speaking)\\n\\nFor LYRICS on screen: Click the small box with 2 lines in it (bottom of video).\\n\\nWATCH:  Counting Numbers: https://youtu.be/W_ocql4lfa0\\nWATCH:  Morning Routine:  https://youtu.be/qiHTfKlF-xE\\nWATCH:  Shapes:  https://youtu.be/B5wiLOkrcyQ\\nWATCH:  Days of the week:  https://youtu.be/f2ftKBo-nos\\nWATCH:  In the Zoo:  https://youtu.be/u6Hx0ScWT3E\\nWATCH:  Red Red Robot:  https://youtu.be/8zaoYPTfgXo\\n\\nA fun interactive song to teach basic emotions to younger learners of English with upbeat music and fun dance actions to reinforce the vocabulary.\\n\\nSUBCRIBE!  http://www.youtube.com/englishthroughmusic\\nFACEBOOK  http://www.facebook.com/etmmadrid\\nTWITTER  http://www.twitter.com/etmmadrid\\nWEBSITE http://www.englishthroughmusic.es \\nSHARE this videos with your friends!\\n\\nLyrics, Music, Song, Dance, Actions and Video copyright.  All rights reserved.\\n\\n\", 'score': 0.75852895}, {'title': \"How are you? I'm fine. (Greeting song) - YouTube\", 'url': 'https://www.youtube.com/watch?v=03XgDWozJOw', 'content': 'How are you? I\\'m fine. (Greeting song) - English song for Kids - Exciting song \\n English Singsing \\n 37662 likes \\n 7036376 views \\n 21 May 2015 \\n https://www.youtube.com/user/englishsingsing9\\nHow are you? - I\\'m fine. - English song for Kids - Let\\'s sing - Sing Along\\n\\nHere is Great Educational Songs & Animations for kids, toddlers, children, babies and EVERYONE!\\nPlease enjoy watching fun & exciting English animation!\\n\\n★ Subscribe us on YouTube: http://goo.gl/gDa963\\n★ More Our Song: https://goo.gl/3uVSGt\\n\\n\\n--- Title: How are you? ---\\n\\nGood morning. Good morning. \\nGood morning. How are you? \\nI\\'m fine. I\\'m fine. I\\'m fine.\\nThank you.\\n\\nGood afternoon. Good afternoon. \\nGood afternoon. How are you? \\nI\\'m not good. I\\'m not good. I\\'m not good. \\nOh, no.\\n\\nGood evening. Good evening. \\nGood evening. How are you? \\nI\\'m great. I\\'m great. I\\'m great.\\nThank you.\\n\\n\\nThanks for checking out the \"English Singsing\".\\n© Amanta Inc. \\n 0 comments', 'score': 0.6897452}, {'title': '9 Ways to Ask “How Are You?” - Grammarly', 'url': 'https://www.grammarly.com/blog/writing-tips/how-are-you/', 'content': \"9 Ways to Ask “How Are You?” with Examples | Grammarly AI at Grammarly AI Writing Tools AI at Grammarly AI Writing Tools Writing How To's Writing With AI Writing How To's Writing With AI Write with Grammarly Conversely, if you’re emailing or messaging your manager who just got back from parental leave, something slightly more formal and targeted might make more sense, like “How are you doing with the new baby?” That way you show interest in their major life event while keeping things professional. And, more than likely, the person will be happy to start a conversation about their work or opinions once you’ve expressed interest. Get Grammarly Grammarly for Teams & Businesses Grammarly for Education AI at Grammarly AI Writing Tools\", 'score': 0.58408195}, {'title': 'What is a good way of responding to “how are you”? - Quora', 'url': 'https://www.quora.com/What-is-a-good-way-of-responding-to-how-are-you', 'content': 'I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why i I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why is that? If I have to go to the store on one of those days and someone asks me I usually say back, “how’s it going?” without any reply to the question.', 'score': 0.5404151}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'How are you?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'How are you? | Emotions song for children | English Through Music', 'url': 'https://www.youtube.com/watch?v=fMR8Hr9Xby4', 'content': \"How are you? |  Emotions song for children | English Through Music\\nEnglishThroughMusic Madrid\\n20900 subscribers\\n9480 likes\\n2593919 views\\n22 Oct 2015\\nLYRICS:\\nI'm happy, I'm happy, I'm happy, I'm very happy (x2)\\nHow are you? How are you? How are you, today?\\nI'm sad, I'm sad, I'm sad I'm very sad (x2)\\nI'm angry\\nI'm tired\\nI'm hungry\\n\\nHow are you?  Song to teach emotions to young children kids with fun dance moves.\\n\\nGo to http://www.englishthroughmusic.es for more information about English Through Music, including more songs, raps, and videos for learning and teaching English.\\n\\nVOCABULARY: Happy, Sad, Angry Tired, Hungry, very, how are you?\\nGRAMMAR: I'm (Instead of 'I am' for correct speaking)\\n\\nFor LYRICS on screen: Click the small box with 2 lines in it (bottom of video).\\n\\nWATCH:  Counting Numbers: https://youtu.be/W_ocql4lfa0\\nWATCH:  Morning Routine:  https://youtu.be/qiHTfKlF-xE\\nWATCH:  Shapes:  https://youtu.be/B5wiLOkrcyQ\\nWATCH:  Days of the week:  https://youtu.be/f2ftKBo-nos\\nWATCH:  In the Zoo:  https://youtu.be/u6Hx0ScWT3E\\nWATCH:  Red Red Robot:  https://youtu.be/8zaoYPTfgXo\\n\\nA fun interactive song to teach basic emotions to younger learners of English with upbeat music and fun dance actions to reinforce the vocabulary.\\n\\nSUBCRIBE!  http://www.youtube.com/englishthroughmusic\\nFACEBOOK  http://www.facebook.com/etmmadrid\\nTWITTER  http://www.twitter.com/etmmadrid\\nWEBSITE http://www.englishthroughmusic.es \\nSHARE this videos with your friends!\\n\\nLyrics, Music, Song, Dance, Actions and Video copyright.  All rights reserved.\\n\\n\", 'score': 0.79637206}, {'title': \"How are you? I'm fine. (Greeting song) - YouTube\", 'url': 'https://www.youtube.com/watch?v=03XgDWozJOw', 'content': 'How are you? I\\'m fine. (Greeting song) - English song for Kids - Exciting song \\n English Singsing \\n 37662 likes \\n 7036376 views \\n 21 May 2015 \\n https://www.youtube.com/user/englishsingsing9\\nHow are you? - I\\'m fine. - English song for Kids - Let\\'s sing - Sing Along\\n\\nHere is Great Educational Songs & Animations for kids, toddlers, children, babies and EVERYONE!\\nPlease enjoy watching fun & exciting English animation!\\n\\n★ Subscribe us on YouTube: http://goo.gl/gDa963\\n★ More Our Song: https://goo.gl/3uVSGt\\n\\n\\n--- Title: How are you? ---\\n\\nGood morning. Good morning. \\nGood morning. How are you? \\nI\\'m fine. I\\'m fine. I\\'m fine.\\nThank you.\\n\\nGood afternoon. Good afternoon. \\nGood afternoon. How are you? \\nI\\'m not good. I\\'m not good. I\\'m not good. \\nOh, no.\\n\\nGood evening. Good evening. \\nGood evening. How are you? \\nI\\'m great. I\\'m great. I\\'m great.\\nThank you.\\n\\n\\nThanks for checking out the \"English Singsing\".\\n© Amanta Inc. \\n 0 comments', 'score': 0.7533401}, {'title': '9 Ways to Ask “How Are You?” with Examples - Grammarly', 'url': 'https://www.grammarly.com/blog/writing-tips/how-are-you/', 'content': \"9 Ways to Ask “How Are You?” with Examples | Grammarly AI at Grammarly AI Writing Tools AI at Grammarly AI Writing Tools Writing How To's Writing With AI Writing How To's Writing With AI Write with Grammarly Conversely, if you’re emailing or messaging your manager who just got back from parental leave, something slightly more formal and targeted might make more sense, like “How are you doing with the new baby?” That way you show interest in their major life event while keeping things professional. And, more than likely, the person will be happy to start a conversation about their work or opinions once you’ve expressed interest. Get Grammarly Grammarly for Teams & Businesses Grammarly for Education AI at Grammarly AI Writing Tools\", 'score': 0.62742686}, {'title': 'What is a good way of responding to “how are you”? - Quora', 'url': 'https://www.quora.com/What-is-a-good-way-of-responding-to-how-are-you', 'content': 'I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why i I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why is that? If I have to go to the store on one of those days and someone asks me I usually say back, “how’s it going?” without any reply to the question.', 'score': 0.5855047}]\u001b[0m\u001b[32;1m\u001b[1;3mI am doing well, thank you for asking. How are you?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hello how are you?',\n",
       " 'output': 'I am doing well, thank you for asking. How are you?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hello how are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector = FAISS.from_documents(documents,embedding)\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='35ba5fdc-396d-47e4-a546-ca14b7650a58', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Get started with LangSmith | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for building production-grade LLM applications.', 'language': 'en'}, page_content='Get started by creating your first prompt.\\nIterate on models and prompts using the Playground.\\nManage prompts programmatically in your application.\\nWas this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'What is LangSmith?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! what is a langsmith?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. \\n'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_executor.invoke({\"input\": \"hi! what is a langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in gangtok'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Weather in Gangtok', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Gangtok', 'region': 'Sikkim', 'country': 'India', 'lat': 27.3333, 'lon': 88.6167, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1742119673, 'localtime': '2025-03-16 15:37'}, 'current': {'last_updated_epoch': 1742119200, 'last_updated': '2025-03-16 15:30', 'temp_c': 16.3, 'temp_f': 61.4, 'is_day': 1, 'condition': {'text': 'Patchy light rain in area with thunder', 'icon': '//cdn.weatherapi.com/weather/64x64/day/386.png', 'code': 1273}, 'wind_mph': 2.9, 'wind_kph': 4.7, 'wind_degree': 275, 'wind_dir': 'W', 'pressure_mb': 1011.0, 'pressure_in': 29.87, 'precip_mm': 1.69, 'precip_in': 0.07, 'humidity': 70, 'cloud': 77, 'feelslike_c': 16.3, 'feelslike_f': 61.4, 'windchill_c': 16.3, 'windchill_f': 61.4, 'heatindex_c': 16.3, 'heatindex_f': 61.4, 'dewpoint_c': 11.0, 'dewpoint_f': 51.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.9, 'gust_mph': 3.8, 'gust_kph': 6.1}}\", 'score': 0.9973297}, {'title': 'gangtok Weather Forecast 16 Mar 2025 - Times of India', 'url': 'https://timesofindia.indiatimes.com/weather/gangtok-weather-forecast-today/737135', 'content': \"Today's Weather in Gangtok: In Gangtok today, the weather is expected to be Fair with a maximum temperature of 25°C and a minimum of 14°C. Sunrise in\", 'score': 0.95488787}, {'title': 'Gangtok weather in March 2025 - Weather25.com', 'url': 'https://www.weather25.com/asia/india/sikkim/gangtok?page=month&month=March', 'content': 'Full weather forecast for Gangtok in March 2025. Check the temperatures ... Mar 16. Patchy rain possible. 0.08 in. 73° / 55° · Monday. Mar 17. Patchy light', 'score': 0.93338853}, {'title': 'Gangtok weather in March 2025 | India: How hot?', 'url': 'https://www.weather2travel.com/india/gangtok/march/', 'content': 'Gangtok weather in March 2025. Expect daytime maximum temperatures of 18°C in Gangtok, India in March based on long-term weather averages.', 'score': 0.9053309}, {'title': '2025 - Gangtok, Sikkim, India Monthly Weather | AccuWeather', 'url': 'https://www.accuweather.com/en/in/gangtok/190542/march-weather/190542', 'content': 'Get the monthly weather forecast for Gangtok, Sikkim, India, including daily high/low, historical averages, to help you plan ahead.', 'score': 0.5414337}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Gangtok on March 16, 2025 is expected to be Patchy light rain in area with thunder. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in gangtok ?',\n",
       " 'output': 'The weather in Gangtok on March 16, 2025 is expected to be Patchy light rain in area with thunder. \\n'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_executor.invoke({\"input\": \"whats the weather in gangtok ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- RAG tool\n",
    "ReAct\n",
    "custom tool with ReAct agent\n",
    "agent code from latest versions(v0.2 and v0.3) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG tool\n",
    "### ReAct\n",
    "### custom tool with ReAct agent\n",
    "### agent code from latest versions(v0.2 and v0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'What is LangSmith?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications. \n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! what is a langsmith?',\n",
       " 'output': 'LangSmith is a platform for building production-grade LLM applications. \\nIt allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\n'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_executor.invoke({\"input\": \"hi! what is a langsmith?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add memory component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'how are you'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'How are you? | Emotions song for children | English Through Music', 'url': 'https://www.youtube.com/watch?v=fMR8Hr9Xby4', 'content': \"How are you? |  Emotions song for children | English Through Music\\nEnglishThroughMusic Madrid\\n20900 subscribers\\n9480 likes\\n2593919 views\\n22 Oct 2015\\nLYRICS:\\nI'm happy, I'm happy, I'm happy, I'm very happy (x2)\\nHow are you? How are you? How are you, today?\\nI'm sad, I'm sad, I'm sad I'm very sad (x2)\\nI'm angry\\nI'm tired\\nI'm hungry\\n\\nHow are you?  Song to teach emotions to young children kids with fun dance moves.\\n\\nGo to http://www.englishthroughmusic.es for more information about English Through Music, including more songs, raps, and videos for learning and teaching English.\\n\\nVOCABULARY: Happy, Sad, Angry Tired, Hungry, very, how are you?\\nGRAMMAR: I'm (Instead of 'I am' for correct speaking)\\n\\nFor LYRICS on screen: Click the small box with 2 lines in it (bottom of video).\\n\\nWATCH:  Counting Numbers: https://youtu.be/W_ocql4lfa0\\nWATCH:  Morning Routine:  https://youtu.be/qiHTfKlF-xE\\nWATCH:  Shapes:  https://youtu.be/B5wiLOkrcyQ\\nWATCH:  Days of the week:  https://youtu.be/f2ftKBo-nos\\nWATCH:  In the Zoo:  https://youtu.be/u6Hx0ScWT3E\\nWATCH:  Red Red Robot:  https://youtu.be/8zaoYPTfgXo\\n\\nA fun interactive song to teach basic emotions to younger learners of English with upbeat music and fun dance actions to reinforce the vocabulary.\\n\\nSUBCRIBE!  http://www.youtube.com/englishthroughmusic\\nFACEBOOK  http://www.facebook.com/etmmadrid\\nTWITTER  http://www.twitter.com/etmmadrid\\nWEBSITE http://www.englishthroughmusic.es \\nSHARE this videos with your friends!\\n\\nLyrics, Music, Song, Dance, Actions and Video copyright.  All rights reserved.\\n\\n\", 'score': 0.75852895}, {'title': '[Greeting] How are you? - Exciting song - Sing along - YouTube', 'url': 'https://www.youtube.com/watch?v=59FTQnfMbIE', 'content': '[Greeting] How are you? - Exciting song - Sing along\\nEnglish Singsing\\n4920000 subscribers\\n13658 likes\\n1912537 views\\n21 Aug 2019\\nhttps://www.youtube.com/user/englishsingsing9\\n[Greeting] How are you? - Exciting song  - English video for Kids - English Sing sing\\n\\nHere is Great Educational Songs & Animations for kids, toddlers, children, babies and EVERYONE!\\nThe each video, that has sound & mute version, is accompanied by English subtitles.\\nPlease enjoy watching fun & exciting English animation!\\n\\n★ Subscribe to us on YouTube: http://goo.gl/gDa963\\n★ More of Our Songs: https://goo.gl/ByGXT2\\n\\n\\n--- Title: How are you? ---\\n\\nGood morning. Good morning. \\nGood morning. How are you? \\nI\\'m fine. I\\'m fine. I\\'m fine.\\nThank you.\\n\\nGood afternoon. Good afternoon. \\nGood afternoon. How are you? \\nI\\'m not good. I\\'m not good. I\\'m not good. \\nOh, no.\\n\\nGood evening. Good evening. \\nGood evening. How are you? \\nI\\'m great. I\\'m great. I\\'m great.\\nThank you.\\n\\n\\nThanks for checking out the \"English Singsing\".\\n© Amanta Inc.\\n\\n', 'score': 0.7004242}, {'title': '9 Ways to Ask “How Are You?” with Examples - Grammarly', 'url': 'https://www.grammarly.com/blog/writing-tips/how-are-you/', 'content': \"9 Ways to Ask “How Are You?” with Examples | Grammarly AI at Grammarly AI Writing Tools AI at Grammarly AI Writing Tools Writing How To's Writing With AI Writing How To's Writing With AI Write with Grammarly Conversely, if you’re emailing or messaging your manager who just got back from parental leave, something slightly more formal and targeted might make more sense, like “How are you doing with the new baby?” That way you show interest in their major life event while keeping things professional. And, more than likely, the person will be happy to start a conversation about their work or opinions once you’ve expressed interest. Get Grammarly Grammarly for Teams & Businesses Grammarly for Education AI at Grammarly AI Writing Tools\", 'score': 0.5677694}, {'title': 'What is a good way of responding to “how are you”? - Quora', 'url': 'https://www.quora.com/What-is-a-good-way-of-responding-to-how-are-you', 'content': 'I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why i I\\'ve had the pleasurable opportunity to have traveled to foreign countries, like Mexico, Canada, and Sweden, where the native people actually do care and find the time to listen if the person being asked answers, “ Well I\\'m not doing good today.\" So why is that? If I have to go to the store on one of those days and someone asks me I usually say back, “how’s it going?” without any reply to the question.', 'score': 0.5404151}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how do you respond to someone who asks how are you?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
      "\n",
      "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "Get started by creating your first prompt.\n",
      "Iterate on models and prompts using the Playground.\n",
      "Manage prompts programmatically in your application.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextQuick StartObservabilityEvalsPrompt EngineeringCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2025 LangChain, Inc.\n",
      "\n",
      "Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'how do you respond to someone who asks how are you?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': \"What is the best reply when somebody asks you 'how are you'?\", 'url': 'https://www.quora.com/What-is-the-best-reply-when-somebody-asks-you-how-are-you', 'content': \"Some ways to reply to “how are you” are: · 1. “I'm good, thanks. · 2. “Doing well, just keeping busy.” · 3. “I'm hanging in there, how's everything with you?”.\", 'score': 0.9203972}, {'title': \"20+ ways to answer the question 'How are you?' - Fast Company\", 'url': 'https://www.fastcompany.com/90634810/5-good-ways-to-answer-the-question-how-are-you', 'content': 'Like with most things, the answer to “How are you?” depends on your situation. Here are some common answers to “How are you?” depending on the scenario you’re in, whether you want a longer conversation, and how you actually are. How are you?” And you?” How are you?” If the person who asks “how are you?” is someone you know well and/or someone you want to have a deeper conversation with, you might consider a response like one of these: How are you?” And yourself?” Variations on “How are you?” and how to answer How about you?” You?” How about you?” If you’re not looking to start a conversation, most of the answers to “How are you?” work perfectly well as a response here.', 'score': 0.8747745}, {'title': 'How To Answer the Question “How Are You?” | Indeed.com', 'url': 'https://www.indeed.com/career-advice/career-development/how-are-you-response', 'content': 'Good: “Good” is the most common answer to the question “How are you?” It is polite and cheerful. · Okay: “Okay” is a neutral answer like “all', 'score': 0.85157084}, {'title': 'How to reply to “How are you?” or “How have you been?”', 'url': 'https://weshouldgettogether.com/blog/how-to-reply-to-how-are-you', 'content': \"I've been alright. How about you? · Hanging in there. How 'bout you? · Doing alright. You? · I'm good. How you been? · Fine as can be expected. You?\", 'score': 0.8173562}, {'title': 'What do you say when someone asks how you are and you ... - Reddit', 'url': 'https://www.reddit.com/r/socialskills/comments/13qy43n/what_do_you_say_when_someone_asks_how_you_are_and/', 'content': \"“I'm glad to be here” “it's good to see you” keep it short and polite and deflect any nosey questions. My experience went fine, most people have\", 'score': 0.8098936}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': \"how to respond to 'how are you' when you're not doing well\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
      "\n",
      "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': \"how to respond when someone asks how are you when you're not doing well\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': \"How should I respond to 'how are you' if I'm not doing well ... - Quora\", 'url': 'https://www.quora.com/How-should-I-respond-to-how-are-you-if-Im-not-doing-well-Should-I-answer-honestly-or-make-a-joke', 'content': \"The correct response, regardless of how you feel is, “I'm fine, how are you?” If they are following protocol, they say, “I'm fine thank you.” It\", 'score': 0.87166095}, {'title': \"How to Respond to “Are You Okay?” When You're NOT Okay\", 'url': 'https://www.healthcentral.com/condition/depression/how-to-respond-to-are-you-okay', 'content': \"Thanks for asking. How are you doing?” If the person persists, offer, “Thanks for your concern but I'd really appreciate your respecting my\", 'score': 0.8455478}, {'title': 'How to reply to “How are you?” or “How have you been?”', 'url': 'https://weshouldgettogether.com/blog/how-to-reply-to-how-are-you', 'content': 'Reason #1: The questions “how are you?” and “how have you been” are frequently used in the United States as a greeting, just like saying “good morning” or “nice to see you.” So it can be frustrating if you wanted to share a real answer to the question, but the other person is already walking away since they never intended to stick around and hear the answer. It’s so ingrained in our culture, that English tutors who help people from other countries prepare for life in the States warn them that when they live in the U.S., people will ask “how are you?” all the time but don’t really care about the answer, so don’t get your feelings hurt if they don’t want to listen to an earnest answer.', 'score': 0.69274646}, {'title': \"How to Answer “How Are You?” When You're Not OK - Wondermind\", 'url': 'https://www.wondermind.com/article/responses-for-when-youre-not-ok/', 'content': 'As awkward as it might seem, sometimes the best answer is an honest one, says therapist Vienna Pharaon, LMFT, author of The Origins of You.', 'score': 0.6894943}, {'title': 'What do you say when someone asks how you are and you ... - Reddit', 'url': 'https://www.reddit.com/r/socialskills/comments/13qy43n/what_do_you_say_when_someone_asks_how_you_are_and/', 'content': 'Reddit - Dive into anything Get App Get the Reddit app Log In Log in to Reddit I’m not ok right now. Reddit Reddit Reddit Communities Best of Reddit Topics Password New to Reddit? Enter the 6-digit code from your authenticator app Check code Enter a 6-digit backup code Backup code Don’t have access to your backup code? Use a code from an authenticator app Check code Reddit is anonymous, so your username is what you’ll go by here. Password Reddit is anonymous, so your username is what you’ll go by here. Password Enter your email address or username and we’ll send you a link to reset your password Choose a Reddit account to continue New password', 'score': 0.5253938}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "```json\n",
      "{\n",
      "\t\"tool_call\": {\n",
      "\t\t\"id\": \"pending\",\n",
      "\t\t\"type\": \"function\",\n",
      "\t\t\"function\": {\n",
      "\t\t\t\"name\": \"tavily_search_results_json\"\n",
      "\t\t\t\"parameters\": {\n",
      "\t\t\t\t\"query\": \"how to respond to 'how are you' when you're not doing well\n",
      "\t\t\t}\n",
      "\t\t}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is sunny how are you?',\n",
       " 'chat_history': [],\n",
       " 'output': '\\n```json\\n{\\n\\t\"tool_call\": {\\n\\t\\t\"id\": \"pending\",\\n\\t\\t\"type\": \"function\",\\n\\t\\t\"function\": {\\n\\t\\t\\t\"name\": \"tavily_search_results_json\"\\n\\t\\t\\t\"parameters\": {\\n\\t\\t\\t\\t\"query\": \"how to respond to \\'how are you\\' when you\\'re not doing well\\n\\t\\t\\t}\\n\\t\\t}\\n```\\n\\n'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! my name is sunny how are you?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"firstchat\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReAct Agent (Reasoning + Acting):\n",
    "Definition:\n",
    "\n",
    "The ReAct framework combines reasoning and acting in a single loop to handle tasks. The agent uses natural language reasoning (thinking through steps) and task actions (performing tasks like calculations or data retrieval).\n",
    "\n",
    "The agent uses a combination of reasoning steps to guide actions in real-time, using feedback from those actions to further inform the next step in reasoning.\n",
    "\n",
    "How it works:\n",
    "\n",
    "Step 1: The agent receives a question or task.\n",
    "Step 2: It reasons aloud (in natural language) about how to solve it.\n",
    "Step 3: Based on its reasoning, it takes actions (e.g., searching a database, calculating something).\n",
    "Step 4: The results of these actions are integrated into its reasoning and may trigger further actions.\n",
    "Step 5: It repeats the process until it arrives at a solution.\n",
    "Key points:\n",
    "\n",
    "Combines thinking and doing (reasoning and actions).\n",
    "Performs iterative steps, updating its process based on action results.\n",
    "Typically handles complex decision-making scenarios.\n",
    "Example:\n",
    "\n",
    "Original task: “Calculate the total number of apples in a basket if there are 4 baskets and 7 apples in each.”\n",
    "Reasoning: \"I need to multiply 4 by 7 to get the total number of apples.\"\n",
    "Action: Perform the multiplication.\n",
    "Result: \"There are 28 apples.\"\n",
    "Reasoning: \"I am done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GoogleSerperAPIWrapper\n  Value error, Did not find serper_api_key, please add an environment variable `SERPER_API_KEY` which contains it, or pass `serper_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m google_search \u001b[38;5;241m=\u001b[39m \u001b[43mGoogleSerperAPIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     Tool(\n\u001b[0;32m      4\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntermediate Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     )\n\u001b[0;32m      9\u001b[0m ]\n",
      "File \u001b[1;32md:\\LangGraph\\Langraph-tutorial\\LangGraph\\venv_langraph\\lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for GoogleSerperAPIWrapper\n  Value error, Did not find serper_api_key, please add an environment variable `SERPER_API_KEY` which contains it, or pass `serper_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "google_search = GoogleSerperAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Intermediate Answer\",\n",
    "        func=google_search.run,\n",
    "        description=\"useful for when you need to ask with search\",\n",
    "        verbose=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_agent = create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=search_agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"Where is the hometown of the 2007 US PGA championship winner and his score?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Agent with Custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_employee_id(name):\n",
    "  \"\"\"\n",
    "  To get employee id, it takes employee name as arguments\n",
    "  name(str): Name of the employee\n",
    "  \"\"\"\n",
    "  fake_employees = {\n",
    "    \"Alice\": \"E001\",\n",
    "    \"Bob\": \"E002\",\n",
    "    \"Charlie\": \"E003\",\n",
    "    \"Diana\": \"E004\",\n",
    "    \"Evan\": \"E005\",\n",
    "    \"Fiona\": \"E006\",\n",
    "    \"George\": \"E007\",\n",
    "    \"Hannah\": \"E008\",\n",
    "    \"Ian\": \"E009\",\n",
    "    \"Jasmine\": \"E010\"}\n",
    "  \n",
    "  return fake_employees.get(name,\"Employee not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tool for the Agent \n",
    "@tool\n",
    "def get_employee_salary(employee_id):\n",
    "  \"\"\"\n",
    "  To get the salary of an employee, it takes employee_id as input and return salary\n",
    "  \"\"\"\n",
    "  employee_salaries = {\n",
    "    \"E001\": 56000,\n",
    "    \"E002\": 47000,\n",
    "    \"E003\": 52000,\n",
    "    \"E004\": 61000,\n",
    "    \"E005\": 45000,\n",
    "    \"E006\": 58000,\n",
    "    \"E007\": 49000,\n",
    "    \"E008\": 53000,\n",
    "    \"E009\": 50000,\n",
    "    \"E010\": 55000\n",
    "    }\n",
    "  return employee_salaries.get(employee_id,\"Employee not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved React Prompt in langchain hub, we could manually type the prompt as well.\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [get_employee_salary, get_employee_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find Evan's employee ID first, then use that to get his salary.\n",
      "Action: get_employee_id\n",
      "Action Input: Evan\u001b[0m\u001b[33;1m\u001b[1;3mE005\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have Evan's employee ID, now I can get his salary.\n",
      "Action: get_employee_salary\n",
      "Action Input: E005\u001b[0m\u001b[36;1m\u001b[1;3m45000\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
      "Final Answer: Evan's salary is 45000 \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the Salary of Evan?', 'output': \"Evan's salary is 45000\"}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is the Salary of Evan?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This given code from the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "search = TavilySearchResults(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qenk', 'function': {'arguments': '{\"query\":\"What is the weather like in Bhisi?\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 3289, 'total_tokens': 3347, 'completion_time': 0.105454545, 'prompt_time': 0.112561576, 'queue_time': 0.23785092600000002, 'total_time': 0.218016121}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ec629d9a-c19b-4162-9619-ada5e9922435-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'What is the weather like in Bhisi?'}, 'id': 'call_qenk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3289, 'output_tokens': 58, 'total_tokens': 3347})]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"title\": \"Weather in Bhisi\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Bhisi\\', \\'region\\': \\'Maharashtra\\', \\'country\\': \\'India\\', \\'lat\\': 20.6333, \\'lon\\': 79.4, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1742120522, \\'localtime\\': \\'2025-03-16 15:52\\'}, \\'current\\': {\\'last_updated_epoch\\': 1742120100, \\'last_updated\\': \\'2025-03-16 15:45\\', \\'temp_c\\': 39.6, \\'temp_f\\': 103.2, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 10.3, \\'wind_kph\\': 16.6, \\'wind_degree\\': 224, \\'wind_dir\\': \\'SW\\', \\'pressure_mb\\': 1006.0, \\'pressure_in\\': 29.71, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 12, \\'cloud\\': 5, \\'feelslike_c\\': 39.3, \\'feelslike_f\\': 102.7, \\'windchill_c\\': 39.6, \\'windchill_f\\': 103.2, \\'heatindex_c\\': 39.3, \\'heatindex_f\\': 102.7, \\'dewpoint_c\\': 5.4, \\'dewpoint_f\\': 41.8, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 3.0, \\'gust_mph\\': 11.8, \\'gust_kph\\': 19.0}}\", \"score\": 0.2586345}, {\"title\": \"Bhisi, Maharashtra, India Monthly Weather | AccuWeather\", \"url\": \"https://www.accuweather.com/en/in/bhisi/199588/january-weather/199588\", \"content\": \"Get the monthly weather forecast for Bhisi, Maharashtra, India, including daily high/low, historical averages, to help you plan ahead.\", \"score\": 0.23720509}]', name='tavily_search_results_json', id='fbe2ad5b-2e7e-4d66-a1a0-8a3f0e442250', tool_call_id='call_qenk', artifact={'query': 'What is the weather like in Bhisi?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Bhisi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Bhisi', 'region': 'Maharashtra', 'country': 'India', 'lat': 20.6333, 'lon': 79.4, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1742120522, 'localtime': '2025-03-16 15:52'}, 'current': {'last_updated_epoch': 1742120100, 'last_updated': '2025-03-16 15:45', 'temp_c': 39.6, 'temp_f': 103.2, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 10.3, 'wind_kph': 16.6, 'wind_degree': 224, 'wind_dir': 'SW', 'pressure_mb': 1006.0, 'pressure_in': 29.71, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 12, 'cloud': 5, 'feelslike_c': 39.3, 'feelslike_f': 102.7, 'windchill_c': 39.6, 'windchill_f': 103.2, 'heatindex_c': 39.3, 'heatindex_f': 102.7, 'dewpoint_c': 5.4, 'dewpoint_f': 41.8, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 3.0, 'gust_mph': 11.8, 'gust_kph': 19.0}}\", 'score': 0.2586345, 'raw_content': None}, {'url': 'https://www.accuweather.com/en/in/bhisi/199588/january-weather/199588', 'title': 'Bhisi, Maharashtra, India Monthly Weather | AccuWeather', 'content': 'Get the monthly weather forecast for Bhisi, Maharashtra, India, including daily high/low, historical averages, to help you plan ahead.', 'score': 0.23720509, 'raw_content': None}], 'response_time': 2.07})]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The weather in Bhisi is sunny with a temperature of 39.6 degrees Celsius or 103.2 degrees Fahrenheit. The wind is blowing from the southwest at 10.3 miles per hour. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 3975, 'total_tokens': 4024, 'completion_time': 0.089090909, 'prompt_time': 0.135421946, 'queue_time': 0.24179770400000003, 'total_time': 0.224512855}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fa8ba507-6654-4ff0-921c-01563d176b5b-0', usage_metadata={'input_tokens': 3975, 'output_tokens': 49, 'total_tokens': 4024})]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='I do not have access to your location.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 4039, 'total_tokens': 4051, 'completion_time': 0.021818182, 'prompt_time': 0.137302872, 'queue_time': 0.237148548, 'total_time': 0.159121054}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-73ca5ea7-7e01-48b3-81df-0f23f98cf0cd-0', usage_metadata={'input_tokens': 4039, 'output_tokens': 12, 'total_tokens': 4051})]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im Bhushan! and i live in Bhisi\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Ask with Search Agent:\n",
    "Definition:\n",
    "\n",
    "This approach allows the AI to ask itself follow-up questions when it doesn't immediately know the answer. It performs a recursive questioning process to break down complex queries into smaller, more manageable ones.\n",
    "Once the AI generates these follow-up questions, it performs an external search (e.g., through Google or an internal database) to gather the necessary information before formulating a response.\n",
    "How it works:\n",
    "\n",
    "Step 1: Receive a complex question.\n",
    "Step 2: The agent identifies sub-questions or follow-up questions.\n",
    "Step 3: It performs a search or fetches answers to these questions from external resources (like a web search).\n",
    "Step 4: The answers are aggregated to provide a complete response.\n",
    "Key points:\n",
    "\n",
    "Emphasizes question decomposition.\n",
    "Relies on external search for sub-questions.\n",
    "Useful for answering open-ended or broad questions where the answer is not immediately available.\n",
    "Example:\n",
    "\n",
    "Original question: “How many moons does Jupiter have?”\n",
    "Sub-question: “What is Jupiter?” (search)\n",
    "Sub-question: “What are moons?” (search)\n",
    "Finally, it retrieves the answer: \"Jupiter has 79 moons.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
